{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb6edd2e-25c6-4c81-936f-fd4cba220928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33f9f1-c0a0-497f-b905-807715c8ca38",
   "metadata": {},
   "source": [
    "## Pre-processing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47d6a2e4-05fb-47ad-bb13-10ac24e6a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.Resize((64, 64)),  \n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c8120-b852-4a08-b04f-275f8a333c5a",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0c6bc0-7bf0-47bb-92eb-b77e5bce804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/Users/shreyamusini/Downloads/emotions_images/train\"\n",
    "test_dir = \"/Users/shreyamusini/Downloads/emotions_images/test\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c4b8dd4-5e26-495d-a8c6-6c10f2bc9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d338b8b-c06e-409e-8744-6a1767187e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 1, 64, 64]), Label shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(train_loader)  # Correct usage\n",
    "inputs, labels = next(data_iter)\n",
    "print(f\"Input shape: {inputs.shape}, Label shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edccc9b8-b658-4c57-bc11-e1432d982b8f",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2dc2ac25-6311-4db0-8334-b8e1c5397579",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  \n",
    "        self.fc1 = nn.Linear(3136, 128) \n",
    "        self.fc2 = nn.Linear(128, 7)\n",
    "        self.relu_3 = nn.ReLU()\n",
    "        self.relu_4 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_1 = self.pool(self.relu_1(self.conv1(x))) \n",
    "        x_2 = self.pool(self.relu_2(self.conv2(x_1))) \n",
    "        x_3 = self.pool(self.relu_3(self.conv3(x_2)))\n",
    "        x_4 = x_3.view(x_3.size(0), -1) \n",
    "        x_5 = self.relu_4(self.fc1(x_4))  \n",
    "        x_6 = self.fc2(x_5)  \n",
    "        return x_6\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4bf3bb-453c-4ca2-9eb6-fc1d5ccc953b",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9f87207f-be1f-4c0b-baa1-7cf7ffbef7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple_cnn = SimpleCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46f53f7-0f32-4d36-9a04-9dc723a68fa5",
   "metadata": {},
   "source": [
    "### Optimizer + Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eea32d99-d692-4f88-b8c1-87a71aa8021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_simple_cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8532d3b7-2c44-48d8-bf58-0d081a5e9d94",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f041d64b-1c26-4a3e-90dc-db4266fbf54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.6571\n",
      "Epoch 2/10, Loss: 1.4372\n",
      "Epoch 3/10, Loss: 1.3115\n",
      "Epoch 4/10, Loss: 1.2105\n",
      "Epoch 5/10, Loss: 1.1323\n",
      "Epoch 6/10, Loss: 1.0538\n",
      "Epoch 7/10, Loss: 0.9847\n",
      "Epoch 8/10, Loss: 0.9142\n",
      "Epoch 9/10, Loss: 0.8492\n",
      "Epoch 10/10, Loss: 0.7828\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_simple_cnn(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {train_losses[-1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f39298e-8a71-40f3-98dd-7b14646ce1e4",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b292004-0e65-4842-b673-21ed32220f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 7200 test images: 54.01%, Test loss: 0.0438\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        outputs = model_simple_cnn(images)\n",
    "        test_loss += loss_func(outputs, labels).item()\n",
    "        correct += (outputs.argmax(1) == labels).type(torch.float).sum().item()\n",
    "print(f'Accuracy of the network on the 7200 test images: {100 * correct / len(test_loader.dataset):.2f}%, Test loss: {test_loss / len(test_loader.dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9566f-94b7-4dca-b2ea-18a41ee8803b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
